{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c3daf4",
   "metadata": {},
   "source": [
    "### Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9ff772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "%pip install gensim\n",
    "%pip install nltk\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052687f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0e8ac973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1b986175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to ./nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab', download_dir='./nltk_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df3768",
   "metadata": {},
   "source": [
    "### Preprocesamiento del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012471cf",
   "metadata": {},
   "source": [
    "Las siguientes funciones se encargan de preparar los textos de los siete libros de Harry Potter para el entrenamiento de modelos de embeddings con Word2Vec.\n",
    "\n",
    "El procesamiento de la función process_books_for_word2vec() sigue los siguientes pasos:\n",
    "\n",
    "1. Lectura de los libros: \n",
    "   Se leen todos los archivos .txt ubicados en la carpeta hp/. Cada archivo representa un libro completo.\n",
    "\n",
    "2. Segmentación en oraciones:  \n",
    "   Se utiliza la función sent_tokenize() de la librería nltk para dividir cada texto en oraciones.\n",
    "\n",
    "3. Tokenización de oraciones:  \n",
    "   Cada oración se tokeniza mediante simple_preprocess de Gensim, que:\n",
    "   - Convierte todas las palabras a minúsculas,\n",
    "   - Convierte todas las palabras a minúsculas,\n",
    "   - Elimina signos de puntuación,\n",
    "   - Elimina palabras con menos de 2 caracteres,\n",
    "   - Opcionalmente elimina acentos (deacc=True).\n",
    "\n",
    "El resultado final es una lista de listas de tokens (oraciones tokenizadas) que puede utilizarse directamente como entrada para entrenar modelos de embeddings con gensim.models.Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "783b52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_books(directory: Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    Lee todos los archivos .txt dentro del directorio especificado.\n",
    "\n",
    "    :param directory: Ruta a la carpeta con los archivos de texto.\n",
    "    :return: Lista de strings, uno por cada libro completo.\n",
    "    \"\"\"\n",
    "    all_text = []\n",
    "    for book_file in sorted(directory.glob(\"*.txt\")):\n",
    "        with open(book_file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            all_text.append(text)\n",
    "    return all_text\n",
    "\n",
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Divide un texto en oraciones usando la segmentación de NLTK.\n",
    "\n",
    "    :param text: Texto unificado.\n",
    "    :return: Lista de oraciones.\n",
    "    \"\"\"\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def tokenize_sentences(sentences: List[str]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Tokeniza cada oración en palabras, eliminando puntuación y pasando a minúsculas.\n",
    "\n",
    "    :param sentences: Lista de oraciones.\n",
    "    :return: Lista de listas de palabras (tokens).\n",
    "    \"\"\"\n",
    "    return [simple_preprocess(sentence, deacc=True) for sentence in sentences]\n",
    "\n",
    "def process_books_for_word2vec(directory: Path) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Procesa todos los libros en un directorio para generar oraciones tokenizadas\n",
    "    aptas para entrenamiento con Word2Vec.\n",
    "\n",
    "    :param directory: Ruta a la carpeta con los libros.\n",
    "    :return: Lista de oraciones tokenizadas.\n",
    "    \"\"\"\n",
    "    raw_books = read_all_books(directory)\n",
    "    all_sentences = []\n",
    "    for book in raw_books:\n",
    "        sentences = split_into_sentences(book)\n",
    "        tokenized = tokenize_sentences(sentences)\n",
    "        all_sentences.extend(tokenized)\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "433990b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Total de oraciones (docs): 66129\n"
     ]
    }
   ],
   "source": [
    "BOOKS_DIR = Path(\"hp\")\n",
    "\n",
    "sentences = process_books_for_word2vec(BOOKS_DIR)\n",
    "\n",
    "print(f\"📄 Total de oraciones (docs): {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538ae83",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3804199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,        # Lista de oraciones tokenizadas\n",
    "    vector_size=100,            # Dimensión de los vectores (puede ajustarse)\n",
    "    window=5,                   # Contexto de palabras (5 a la izquierda y 5 a la derecha)\n",
    "    min_count=5,                # Palabras con frecuencia < 5 son ignoradas\n",
    "    workers=4,                  # Número de hilos de procesamiento paralelo\n",
    "    sg=1,                       # Skip-gram (1) en lugar de CBOW (0)\n",
    "    epochs=10                   # Número de pasadas completas sobre el corpus\n",
    ")\n",
    "\n",
    "w2v_model.save(\"hp_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e344f80",
   "metadata": {},
   "source": [
    "### Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ceff0",
   "metadata": {},
   "source": [
    "#### Similitud semántica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7875b98",
   "metadata": {},
   "source": [
    "Se realiza una exploración del espacio de embeddings entrenado con Word2Vec usando el método:\n",
    "\n",
    "```python\n",
    "w2v_model.wv.most_similar('palabra_objetivo')\n",
    "```\n",
    "\n",
    "Este devuelve las palabras que tienen mayor similitud coseno con el vector asociado a la palabra dada. Es decir, aquellas que aparecen en contextos similares y, por lo tanto, tienen un significado o función similar dentro del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "766831e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lord', 0.7069865465164185),\n",
       " ('wormtail', 0.6690964698791504),\n",
       " ('elder', 0.6340605616569519),\n",
       " ('nagini', 0.6284155249595642),\n",
       " ('pettigrew', 0.6125122904777527),\n",
       " ('understands', 0.611863911151886),\n",
       " ('weakness', 0.6112457513809204),\n",
       " ('dumbledore', 0.6090002655982971),\n",
       " ('quirrell', 0.6040014028549194),\n",
       " ('dumbledores', 0.6036220192909241)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('voldemort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d8f67bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ravenclaw', 0.72437983751297),\n",
       " ('slytherin', 0.7099413275718689),\n",
       " ('points', 0.698464572429657),\n",
       " ('hufflepuff', 0.6680050492286682),\n",
       " ('tower', 0.6656131148338318),\n",
       " ('spectators', 0.6427123546600342),\n",
       " ('locker', 0.6376153230667114),\n",
       " ('championship', 0.6364508867263794),\n",
       " ('chaser', 0.6340674161911011),\n",
       " ('captain', 0.6254349946975708)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('gryffindor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8eff5329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('match', 0.7520051002502441),\n",
       " ('season', 0.7355700135231018),\n",
       " ('session', 0.6944305896759033),\n",
       " ('team', 0.6925305128097534),\n",
       " ('seeker', 0.6807789206504822),\n",
       " ('cup', 0.6791298985481262),\n",
       " ('player', 0.6632496118545532),\n",
       " ('winning', 0.6535742878913879),\n",
       " ('practice', 0.6534658670425415),\n",
       " ('wins', 0.6499863862991333)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('quidditch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "521bbce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ron', 0.654772162437439),\n",
       " ('parvati', 0.6493538618087769),\n",
       " ('encouragingly', 0.6356828808784485),\n",
       " ('hotly', 0.6309463977813721),\n",
       " ('unconvinced', 0.6253873109817505),\n",
       " ('incredulously', 0.624884843826294),\n",
       " ('doubtfully', 0.6231666803359985),\n",
       " ('lavender', 0.6096546649932861),\n",
       " ('grumpily', 0.6076415181159973),\n",
       " ('fearfully', 0.6051589250564575)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('hermione')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa555c0",
   "metadata": {},
   "source": [
    "Se detectan palabras \"intrusas\" utilizando el método:\n",
    "\n",
    "```python\n",
    "w2v_model.wv.doesnt_match(lista_de_palabras)\n",
    "```\n",
    "\n",
    "Este sirve para detectar cuál de las palabras no encaja semánticamente con el resto. Internamente, Word2Vec calcula el vector promedio de todas las palabras y devuelve aquella cuyo vector está más alejado del centroide de los demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "07c1af2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'voldemort'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['harry', 'ron', 'hermione', 'voldemort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "93f4250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weasley'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['malfoy', 'riddle', 'lestrange', 'weasley'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a7e38",
   "metadata": {},
   "source": [
    "#### Semántica relacional mediante analogías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347c44c",
   "metadata": {},
   "source": [
    "Una de las capacidades más interesantes de los embeddings entrenados con Word2Vec es su habilidad para capturar relaciones semánticas vectoriales mediante operaciones aritméticas simples. Se utiliza el método:\n",
    "\n",
    "```python\n",
    "w2v_model.wv.most_similar(positive=[...], negative=[...])\n",
    "```\n",
    "\n",
    "Este permite construir este tipo de analogías mediante sumas y restas de vectores. Internamente, calcula:\n",
    "\n",
    "$$\n",
    "\\text{resultado} = \\sum \\text{(positivos)} - \\sum \\text{(negativos)}\n",
    "$$\n",
    "\n",
    "y devuelve las palabras más similares al vector resultante, usando cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "26f53be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crabbe', 0.7475333213806152),\n",
       " ('pansy', 0.5595075488090515),\n",
       " ('parkinson', 0.52581387758255),\n",
       " ('guffawed', 0.504027247428894),\n",
       " ('cronies', 0.48564016819000244),\n",
       " ('george', 0.48499131202697754),\n",
       " ('zabini', 0.4760032296180725),\n",
       " ('sniggering', 0.4485675096511841),\n",
       " ('fred', 0.44503194093704224),\n",
       " ('gregory', 0.444950670003891)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"ron\", \"goyle\"], negative=[\"harry\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
