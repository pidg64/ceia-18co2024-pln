{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c3daf4",
   "metadata": {},
   "source": [
    "### Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ff772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "%pip install gensim\n",
    "%pip install nltk\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a052687f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e8ac973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b986175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to ./nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab', download_dir='./nltk_data')\n",
    "nltk.data.path.append('./nltk_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df3768",
   "metadata": {},
   "source": [
    "### Preprocesamiento del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012471cf",
   "metadata": {},
   "source": [
    "Las siguientes funciones se encargan de preparar los textos de los siete libros de Harry Potter para el entrenamiento de modelos de embeddings con Word2Vec.\n",
    "\n",
    "El procesamiento de la función process_books_for_word2vec() sigue los siguientes pasos:\n",
    "\n",
    "1. Lectura de los libros: \n",
    "   Se leen todos los archivos .txt ubicados en la carpeta hp/. Cada archivo representa un libro completo.\n",
    "\n",
    "2. Segmentación en oraciones:  \n",
    "   Se utiliza la función sent_tokenize() de la librería nltk para dividir cada texto en oraciones.\n",
    "\n",
    "3. Tokenización de oraciones:  \n",
    "   Cada oración se tokeniza mediante simple_preprocess de Gensim, que:\n",
    "   - Convierte todas las palabras a minúsculas,\n",
    "   - Convierte todas las palabras a minúsculas,\n",
    "   - Elimina signos de puntuación,\n",
    "   - Elimina palabras con menos de 2 caracteres,\n",
    "   - Opcionalmente elimina acentos (deacc=True).\n",
    "\n",
    "El resultado final es una lista de listas de tokens (oraciones tokenizadas) que puede utilizarse directamente como entrada para entrenar modelos de embeddings con gensim.models.Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "783b52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_books(directory: Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    Lee todos los archivos .txt dentro del directorio especificado.\n",
    "\n",
    "    :param directory: Ruta a la carpeta con los archivos de texto.\n",
    "    :return: Lista de strings, uno por cada libro completo.\n",
    "    \"\"\"\n",
    "    all_text = []\n",
    "    for book_file in sorted(directory.glob(\"*.txt\")):\n",
    "        with open(book_file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            all_text.append(text)\n",
    "    return all_text\n",
    "\n",
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Divide un texto en oraciones usando la segmentación de NLTK.\n",
    "\n",
    "    :param text: Texto unificado.\n",
    "    :return: Lista de oraciones.\n",
    "    \"\"\"\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def tokenize_sentences(sentences: List[str]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Tokeniza cada oración en palabras, eliminando puntuación y pasando a minúsculas.\n",
    "\n",
    "    :param sentences: Lista de oraciones.\n",
    "    :return: Lista de listas de palabras (tokens).\n",
    "    \"\"\"\n",
    "    return [simple_preprocess(sentence, deacc=True) for sentence in sentences]\n",
    "\n",
    "def process_books_for_word2vec(directory: Path) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Procesa todos los libros en un directorio para generar oraciones tokenizadas\n",
    "    aptas para entrenamiento con Word2Vec.\n",
    "\n",
    "    :param directory: Ruta a la carpeta con los libros.\n",
    "    :return: Lista de oraciones tokenizadas.\n",
    "    \"\"\"\n",
    "    raw_books = read_all_books(directory)\n",
    "    all_sentences = []\n",
    "    for book in raw_books:\n",
    "        sentences = split_into_sentences(book)\n",
    "        tokenized = tokenize_sentences(sentences)\n",
    "        all_sentences.extend(tokenized)\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "433990b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de oraciones (docs): 66129\n"
     ]
    }
   ],
   "source": [
    "BOOKS_DIR = Path(\"hp\")\n",
    "\n",
    "sentences = process_books_for_word2vec(BOOKS_DIR)\n",
    "\n",
    "print(f\"Total de oraciones (docs): {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538ae83",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3804199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde 'hp_word2vec.model'.\n"
     ]
    }
   ],
   "source": [
    "if Path(\"hp_word2vec.model\").exists():\n",
    "    w2v_model = Word2Vec.load(\"hp_word2vec.model\")\n",
    "    print(\"Modelo cargado desde 'hp_word2vec.model'.\")\n",
    "else:\n",
    "    print(\n",
    "        \"El archivo 'hp_word2vec.model' no existe. Se entrena y posteriormente \"\n",
    "        \"guarda el modelo.\"\n",
    "    )\n",
    "    w2v_model = Word2Vec(\n",
    "        sentences=sentences,        # Lista de oraciones tokenizadas\n",
    "        vector_size=100,            # Dimensión de los vectores (puede ajustarse)\n",
    "        window=5,                   # Contexto de palabras (5 a la izquierda y 5 a la derecha)\n",
    "        min_count=5,                # Palabras con frecuencia < 5 son ignoradas\n",
    "        workers=4,                  # Número de hilos de procesamiento paralelo\n",
    "        sg=1,                       # Skip-gram (1) en lugar de CBOW (0)\n",
    "        epochs=10                   # Número de pasadas completas sobre el corpus\n",
    "    )\n",
    "    w2v_model.save(\"hp_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4d1280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de words distintas en el corpus: 8945\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de words distintas en el corpus: {len(w2v_model.wv.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e344f80",
   "metadata": {},
   "source": [
    "### Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ceff0",
   "metadata": {},
   "source": [
    "#### Similitud semántica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7875b98",
   "metadata": {},
   "source": [
    "Se realiza una exploración del espacio de embeddings entrenado con Word2Vec usando el método:\n",
    "\n",
    "```python\n",
    "w2v_model.wv.most_similar('palabra_objetivo')\n",
    "```\n",
    "\n",
    "Este devuelve las palabras que tienen mayor similitud coseno con el vector asociado a la palabra dada. Es decir, aquellas que aparecen en contextos similares y, por lo tanto, tienen un significado o función similar dentro del corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "766831e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lord', 0.6861612796783447),\n",
       " ('wormtail', 0.6722836494445801),\n",
       " ('existed', 0.6607217192649841),\n",
       " ('nagini', 0.646398663520813),\n",
       " ('dumbledores', 0.6296890377998352),\n",
       " ('weakness', 0.6190014481544495),\n",
       " ('quirrell', 0.6127578020095825),\n",
       " ('dumbledore', 0.6066954731941223),\n",
       " ('immortality', 0.6058774590492249),\n",
       " ('gregorovitch', 0.6045021414756775)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('voldemort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8f67bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ravenclaw', 0.7492218017578125),\n",
       " ('slytherin', 0.7464183568954468),\n",
       " ('tower', 0.7013822197914124),\n",
       " ('points', 0.6744107007980347),\n",
       " ('hufflepuff', 0.6610947251319885),\n",
       " ('possession', 0.6421495079994202),\n",
       " ('goalposts', 0.635903000831604),\n",
       " ('chaser', 0.6338302493095398),\n",
       " ('championship', 0.6316118240356445),\n",
       " ('captain', 0.6067246794700623)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('gryffindor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eff5329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('match', 0.7592418193817139),\n",
       " ('team', 0.7158492207527161),\n",
       " ('season', 0.7112775444984436),\n",
       " ('seeker', 0.6902853846549988),\n",
       " ('performance', 0.6629675030708313),\n",
       " ('supplies', 0.653921365737915),\n",
       " ('session', 0.6528952121734619),\n",
       " ('cup', 0.6450088024139404),\n",
       " ('practice', 0.6439194083213806),\n",
       " ('tryouts', 0.6433351039886475)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('quidditch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "521bbce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('parvati', 0.6295778155326843),\n",
       " ('lavender', 0.6274082660675049),\n",
       " ('ron', 0.6222432851791382),\n",
       " ('ginny', 0.620416522026062),\n",
       " ('luna', 0.6087537407875061),\n",
       " ('encouragingly', 0.6078932285308838),\n",
       " ('grabbing', 0.6073558926582336),\n",
       " ('incredulously', 0.5881399512290955),\n",
       " ('perplexed', 0.587963879108429),\n",
       " ('uh', 0.5838364362716675)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('hermione')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698fb097",
   "metadata": {},
   "source": [
    "Puede observarse que los resultados anteriores muestran que el modelo capturó correctamente relaciones semánticas relevantes:\n",
    "\n",
    "- Por ejemplo, voldemort aparece junto a wormtail y nagini, personajes fuertemente ligados a él en la historia.\n",
    "\n",
    "- gryffindor se asocia con otras casas como ravenclaw y slytherin, reflejando la estructura del colegio.\n",
    "\n",
    "- quidditch muestra proximidad con términos como match y seeker, indicando que el modelo entendió bien el contexto del deporte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd19277",
   "metadata": {},
   "source": [
    "#### Detección de outlier semánticos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa555c0",
   "metadata": {},
   "source": [
    "Se detectan palabras \"intrusas\" utilizando el método:\n",
    "\n",
    "```python\n",
    "w2v_model.wv.doesnt_match(lista_de_palabras)\n",
    "```\n",
    "\n",
    "Este sirve para detectar cuál de las palabras no encaja semánticamente con el resto. Internamente, Word2Vec calcula el vector promedio de todas las palabras y devuelve aquella cuyo vector está más alejado del centroide de los demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07c1af2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'voldemort'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['harry', 'ron', 'hermione', 'voldemort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93f4250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weasley'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['malfoy', 'riddle', 'lestrange', 'weasley'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591c80e",
   "metadata": {},
   "source": [
    "Los resultados obtenidos con doesnt_match() muestran que el modelo logra identificar correctamente qué palabra no encaja semánticamente en un grupo:\n",
    "\n",
    "- En el primer ejemplo, 'voldemort' es detectado como intruso frente a 'harry', 'ron' y 'hermione', que conforman el trío protagonista, mientras que Voldemort es su antagonista.\n",
    "\n",
    "- En el segundo ejemplo, 'weasley' es separado del grupo formado por 'malfoy', 'riddle' y 'lestrange', todos personajes ligados a los villanos, lo que refleja una clara separación semántica entre \"bandos\" en el corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a7e38",
   "metadata": {},
   "source": [
    "#### Semántica relacional mediante analogías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347c44c",
   "metadata": {},
   "source": [
    "Una de las capacidades más interesantes de los embeddings entrenados con Word2Vec es su habilidad para capturar relaciones semánticas vectoriales mediante operaciones aritméticas simples. Se utiliza el método:\n",
    "\n",
    "```python\n",
    "w2v_model.wv.most_similar(positive=[...], negative=[...])\n",
    "```\n",
    "\n",
    "Este permite construir este tipo de analogías mediante sumas y restas de vectores. Internamente, calcula:\n",
    "\n",
    "$$\n",
    "\\text{resultado} = \\sum \\text{(positivos)} - \\sum \\text{(negativos)}\n",
    "$$\n",
    "\n",
    "y devuelve las palabras más similares al vector resultante, usando cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26f53be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crabbe', 0.7852412462234497),\n",
       " ('pansy', 0.5699352025985718),\n",
       " ('guffawed', 0.5448824763298035),\n",
       " ('parkinson', 0.5382308959960938),\n",
       " ('zabini', 0.5377624034881592),\n",
       " ('gregory', 0.49223610758781433),\n",
       " ('cronies', 0.4894270598888397),\n",
       " ('george', 0.4674016535282135),\n",
       " ('neighbours', 0.46551889181137085),\n",
       " ('malfoy', 0.4628375768661499)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"ron\", \"goyle\"], negative=[\"harry\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e353d2",
   "metadata": {},
   "source": [
    "En esta prueba se buscó resolver la analogía “Ron es a Harry como ¿quién es a Goyle?”\n",
    "\n",
    "El modelo devolvió como primer resultado a 'crabbe', lo cual es coherente con el universo narrativo: así como Ron es el compañero cercano de Harry, Crabbe cumple un rol equivalente respecto de Goyle. Esto sugiere que el modelo capturó correctamente relaciones de co-ocurrencia y agrupaciones de personajes consistentes dentro del corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
